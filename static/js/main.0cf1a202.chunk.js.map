{"version":3,"sources":["component/CanvasFrame.js","index.js"],"names":["CanvasFrame","props","_this","Object","classCallCheck","this","possibleConstructorReturn","getPrototypeOf","call","detectFrame","video","model","detect","then","predictions","renderPredictions","requestAnimationFrame","ctx","canvasRef","current","getContext","clearRect","canvas","width","height","font","textBaseline","forEach","prediction","x","bbox","y","strokeStyle","lineWidth","strokeRect","fillStyle","fillText","class","scoreText","score","toFixed","state","videoRef","React","createRef","_this2","navigator","mediaDevices","getUserMedia","webCamPromise","audio","facingMode","stream","window","srcObject","Promise","resolve","reject","onloadedmetadata","modelPromise","cocoSsd","all","values","catch","error","console","alert","react_default","a","createElement","className","autoPlay","muted","ref","Component","root","document","getElementById","ReactDOM","render","CanvasFrame_CanvasFrame"],"mappings":"+QAIqBA,oBACjB,SAAAA,EAAYC,GAAO,IAAAC,EAAA,OAAAC,OAAAC,EAAA,EAAAD,CAAAE,KAAAL,IACfE,EAAAC,OAAAG,EAAA,EAAAH,CAAAE,KAAAF,OAAAI,EAAA,EAAAJ,CAAAH,GAAAQ,KAAAH,KAAMJ,KAqCVQ,YAAc,SAACC,EAAOC,GAClBA,EAAMC,OAAOF,GAAOG,KAAK,SAAAC,GACrBZ,EAAKa,kBAAkBD,GACvBE,sBAAsB,WAClBd,EAAKO,YAAYC,EAAOC,QA1CjBT,EA+CnBa,kBAAoB,SAAAD,GAChB,IAAMG,EAAMf,EAAKgB,UAAUC,QAAQC,WAAW,MAC9CH,EAAII,UAAU,EAAG,EAAGJ,EAAIK,OAAOC,MAAON,EAAIK,OAAOE,QAGjDP,EAAIQ,KADS,aAEbR,EAAIS,aAAe,MACnBZ,EAAYa,QAAQ,SAAAC,GAChB,IAAMC,EAAID,EAAWE,KAAK,GACpBC,EAAIH,EAAWE,KAAK,GACpBP,EAAQK,EAAWE,KAAK,GACxBN,EAASI,EAAWE,KAAK,GAG/Bb,EAAIe,YAAc,UAClBf,EAAIgB,UAAY,EAChBhB,EAAIiB,WAAWL,EAAGE,EAAGR,EAAOC,GAG5BP,EAAIkB,UAAY,UAChBlB,EAAImB,SAASR,EAAWS,MAAOR,EAAGE,GAClC,IACIO,EAAoB,KADXV,EAAWW,OAASX,EAAWW,MAAMC,QAAQ,IAAO,GACnC,IAC9BvB,EAAImB,SAASE,EAAWT,EAAGE,EAAI,OApEnC7B,EAAKuC,MAAQ,GACbvC,EAAKwC,SAAWC,IAAMC,YACtB1C,EAAKgB,UAAYyB,IAAMC,YAJR1C,mFAOC,IAAA2C,EAAAxC,KAChB,GAAIyC,UAAUC,cAAgBD,UAAUC,aAAaC,aAAc,CAC/D,IAAMC,EAAgBH,UAAUC,aAC3BC,aAAa,CACVE,OAAO,EACPxC,MAAO,CACHyC,WAAY,UAGnBtC,KAAK,SAAAuC,GAGF,OAFAC,OAAOD,OAASA,EAChBP,EAAKH,SAASvB,QAAQmC,UAAYF,EAC3B,IAAIG,QAAQ,SAACC,EAASC,GACzBZ,EAAKH,SAASvB,QAAQuC,iBAAmB,WACrCF,SAIVG,EAAeC,MACrBL,QAAQM,IAAI,CAACF,EAAcV,IACtBpC,KAAK,SAAAiD,GACFjB,EAAKpC,YAAYoC,EAAKH,SAASvB,QAAS2C,EAAO,MAElDC,MAAM,SAAAC,GACHC,QAAQD,MAAMA,UAGtBE,MAAM,yDAyCV,OACIC,EAAAC,EAAAC,cAAA,OAAKC,UAAU,kBACXH,EAAAC,EAAAC,cAAA,SAAOC,UAAU,QAAQC,UAAQ,EAACC,OAAK,EAACC,IAAKpE,KAAKqC,SAAUnB,MAAM,MAAMC,OAAO,QAC/E2C,EAAAC,EAAAC,cAAA,UAAQC,UAAU,QAAQG,IAAKpE,KAAKa,UAAWK,MAAM,MAAMC,OAAO,gBA/EzCmB,IAAM+B,YCCzCC,EAAOC,SAASC,eAAe,QACrCC,IAASC,OAAOZ,EAAAC,EAAAC,cAACW,EAAD,MAAiBL","file":"static/js/main.0cf1a202.chunk.js","sourcesContent":["import React from 'react';\nimport * as cocoSsd from '@tensorflow-models/coco-ssd';\nimport '@tensorflow/tfjs';\n\nexport default class CanvasFrame extends React.Component {\n    constructor(props) {\n        super(props);\n        this.state = {};\n        this.videoRef = React.createRef();\n        this.canvasRef = React.createRef();\n    }\n\n    componentDidMount() {\n        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {\n            const webCamPromise = navigator.mediaDevices\n                .getUserMedia({\n                    audio: false,\n                    video: {\n                        facingMode: 'user'\n                    }\n                })\n                .then(stream => {\n                    window.stream = stream;\n                    this.videoRef.current.srcObject = stream;\n                    return new Promise((resolve, reject) => {\n                        this.videoRef.current.onloadedmetadata = () => {\n                            resolve();\n                        };\n                    });\n                });\n            const modelPromise = cocoSsd.load();\n            Promise.all([modelPromise, webCamPromise])\n                .then(values => {\n                    this.detectFrame(this.videoRef.current, values[0]);\n                })\n                .catch(error => {\n                    console.error(error);\n                });\n        } else {\n            alert('Video not supported.');\n        }\n    }\n\n    detectFrame = (video, model) => {\n        model.detect(video).then(predictions => {\n            this.renderPredictions(predictions);\n            requestAnimationFrame(() => {\n                this.detectFrame(video, model);\n            });\n        });\n    };\n\n    renderPredictions = predictions => {\n        const ctx = this.canvasRef.current.getContext('2d');\n        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n        // Font options.\n        const font = '16px arial';\n        ctx.font = font;\n        ctx.textBaseline = 'top';\n        predictions.forEach(prediction => {\n            const x = prediction.bbox[0];\n            const y = prediction.bbox[1];\n            const width = prediction.bbox[2];\n            const height = prediction.bbox[3];\n\n            // Draw the bounding box.\n            ctx.strokeStyle = '#ff0000';\n            ctx.lineWidth = 2;\n            ctx.strokeRect(x, y, width, height);\n\n            // Render detected text & accuracy\n            ctx.fillStyle = '#000000';\n            ctx.fillText(prediction.class, x, y);\n            let score = (prediction.score && prediction.score.toFixed(2)) || 0;\n            let scoreText = score * 100 + '%';\n            ctx.fillText(scoreText, x, y + 20);\n        });\n    };\n\n    render() {\n        return (\n            <div className='main-container'>\n                <video className='video' autoPlay muted ref={this.videoRef} width='600' height='500' />\n                <canvas className='video' ref={this.canvasRef} width='600' height='500' />\n            </div>\n        );\n    }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './styles.css';\nimport CanvasFrame from './component/CanvasFrame';\n\nconst root = document.getElementById('root');\nReactDOM.render(<CanvasFrame />, root);\n"],"sourceRoot":""}